T[                  _Interpreter.c(   42): interpreter_loadCore            ] [ START ]interpreter_loadCore
T[                  _Interpreter.c(   28): Interpreter_addFunction         ] [ START ]Interpreter_addFunction
T[                  _Interpreter.c(   32): Interpreter_addFunction         ] [  END  ]Interpreter_addFunction
T[                  _Interpreter.c(   28): Interpreter_addFunction         ] [ START ]Interpreter_addFunction
T[                  _Interpreter.c(   32): Interpreter_addFunction         ] [  END  ]Interpreter_addFunction
T[                  _Interpreter.c(   45): interpreter_loadCore            ] [  END  ]interpreter_loadCore
T[                  _Interpreter.c(  107): Interpreter_compile             ] [ START ]Interpreter_compile
T[                    _Tokenizer.c(  128): tokenizer_new                   ] [ START ]tokenizer_new
T[                    _Tokenizer.c(  149): tokenizer_new                   ] [  END  ]tokenizer_new
T[                    _Tokenizer.c( 1300): tokenizer_parse                 ] [ START ]tokenizer_parse
T[                    _Tokenizer.c(  613): parseIdentifier                 ] [ START ]parseIdentifier
T[                    _Tokenizer.c(  308): parseReserved                   ] [ START ]parseReserved
T[                    _Tokenizer.c(  450): parseReserved                   ] [  END  ]parseReserved
T[                    _Tokenizer.c(  462): parseVariableOrFunction         ] [ START ]parseVariableOrFunction
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c(  507): parseVariableOrFunction         ] [  END  ]parseVariableOrFunction
T[                    _Tokenizer.c(  670): parseIdentifier                 ] [  END  ]parseIdentifier
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(()
T[                    _Tokenizer.c( 1108): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_LEFT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(")
T[                    _Tokenizer.c( 1213): parseOther                      ] Try string literal.
T[                    _Tokenizer.c(  917): parseStringLiteral              ] [ START ]parseStringLiteral
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c(  968): parseStringLiteral              ] [  END  ]parseStringLiteral
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.())
T[                    _Tokenizer.c( 1114): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_RIGHT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(
)
T[                    _Tokenizer.c( 1220): parseOther                      ] Create 'TOKEN_TYPE_NEW_LINE'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1229): parseOther                      ] Try indent/dedent literal.
T[                    _Tokenizer.c(  979): parseIndentDedent               ] [ START ]parseIndentDedent
T[                    _Tokenizer.c( 1077): parseIndentDedent               ] [  END  ]parseIndentDedent
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c(  613): parseIdentifier                 ] [ START ]parseIdentifier
T[                    _Tokenizer.c(  308): parseReserved                   ] [ START ]parseReserved
T[                    _Tokenizer.c(  450): parseReserved                   ] [  END  ]parseReserved
T[                    _Tokenizer.c(  462): parseVariableOrFunction         ] [ START ]parseVariableOrFunction
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c(  507): parseVariableOrFunction         ] [  END  ]parseVariableOrFunction
T[                    _Tokenizer.c(  670): parseIdentifier                 ] [  END  ]parseIdentifier
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(()
T[                    _Tokenizer.c( 1108): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_LEFT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(")
T[                    _Tokenizer.c( 1213): parseOther                      ] Try string literal.
T[                    _Tokenizer.c(  917): parseStringLiteral              ] [ START ]parseStringLiteral
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c(  968): parseStringLiteral              ] [  END  ]parseStringLiteral
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.())
T[                    _Tokenizer.c( 1114): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_RIGHT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(
)
T[                    _Tokenizer.c( 1220): parseOther                      ] Create 'TOKEN_TYPE_NEW_LINE'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1229): parseOther                      ] Try indent/dedent literal.
T[                    _Tokenizer.c(  979): parseIndentDedent               ] [ START ]parseIndentDedent
T[                    _Tokenizer.c( 1077): parseIndentDedent               ] [  END  ]parseIndentDedent
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c(  613): parseIdentifier                 ] [ START ]parseIdentifier
T[                    _Tokenizer.c(  308): parseReserved                   ] [ START ]parseReserved
T[                    _Tokenizer.c(  450): parseReserved                   ] [  END  ]parseReserved
T[                    _Tokenizer.c(  462): parseVariableOrFunction         ] [ START ]parseVariableOrFunction
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c(  507): parseVariableOrFunction         ] [  END  ]parseVariableOrFunction
T[                    _Tokenizer.c(  670): parseIdentifier                 ] [  END  ]parseIdentifier
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(()
T[                    _Tokenizer.c( 1108): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_LEFT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(")
T[                    _Tokenizer.c( 1213): parseOther                      ] Try string literal.
T[                    _Tokenizer.c(  917): parseStringLiteral              ] [ START ]parseStringLiteral
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c(  968): parseStringLiteral              ] [  END  ]parseStringLiteral
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(,)
T[                    _Tokenizer.c( 1186): parseOther                      ] Try comma literal.
T[                    _Tokenizer.c( 1206): parseOther                      ] Create 'TOKEN_TYPE_COMMA'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c(  613): parseIdentifier                 ] [ START ]parseIdentifier
T[                    _Tokenizer.c(  308): parseReserved                   ] [ START ]parseReserved
T[                    _Tokenizer.c(  450): parseReserved                   ] [  END  ]parseReserved
T[                    _Tokenizer.c(  462): parseVariableOrFunction         ] [ START ]parseVariableOrFunction
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c(  507): parseVariableOrFunction         ] [  END  ]parseVariableOrFunction
T[                    _Tokenizer.c(  670): parseIdentifier                 ] [  END  ]parseIdentifier
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(()
T[                    _Tokenizer.c( 1108): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_LEFT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.())
T[                    _Tokenizer.c( 1114): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_RIGHT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.())
T[                    _Tokenizer.c( 1114): parseOther                      ] Create 'TOKEN_TYPE_PARENTHESIS_RIGHT'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1088): parseOther                      ] [ START ]parseOther
T[                    _Tokenizer.c( 1102): parseOther                      ] Check first charactor.(
)
T[                    _Tokenizer.c( 1220): parseOther                      ] Create 'TOKEN_TYPE_NEW_LINE'
T[                    _Tokenizer.c(   81): token_new                       ] [ START ]token_new
T[                    _Tokenizer.c(   87): token_new                       ] [  END  ]token_new
T[                    _Tokenizer.c( 1229): parseOther                      ] Try indent/dedent literal.
T[                    _Tokenizer.c(  979): parseIndentDedent               ] [ START ]parseIndentDedent
T[                    _Tokenizer.c( 1077): parseIndentDedent               ] [  END  ]parseIndentDedent
T[                    _Tokenizer.c( 1253): parseOther                      ] [  END  ]parseOther
T[                    _Tokenizer.c( 1359): tokenizer_parse                 ] result = 1
T[                    _Tokenizer.c( 1360): tokenizer_parse                 ] [  END  ]tokenizer_parse
T[                       _Parser.c(   13): parser_new                      ] [ START ]parser_new
T[                       _Parser.c(   22): parser_new                      ] [  END  ]parser_new
T[                       _Parser.c(  163): parser_parse                    ] [ START ]parser_parse
T[                    _Statement.c(   74): statement_parse                 ] [ START ]statement_parse
T[                    _Statement.c(  177): statement_parse                 ] [  END  ]statement_parse
